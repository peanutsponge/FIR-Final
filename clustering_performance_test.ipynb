{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_extractor = cv.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_descriptors_map = f'bins/{descriptor_extractor.__class__.__name__}-descriptors_map.bin'\n",
    "print(filename_descriptors_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if descriptors are already computed\n",
    "if os.path.isfile(filename_descriptors_map):\n",
    "    print('Loading descriptors')\n",
    "    # load pre-computed descriptors\n",
    "    f = open(filename_descriptors_map, 'rb')\n",
    "    descriptors = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    print('Computing descriptors')\n",
    "    # Initialize the data structure that will contain all the descriptors\n",
    "    descriptors = None\n",
    "    # Loop over map images\n",
    "    for img_name in m_imgs:\n",
    "        img = cv.imread(os.path.join('data02/', img_name))\n",
    "\n",
    "        # Extract descriptors\n",
    "        keypoints_img, descriptors_img = descriptor_extractor.detectAndCompute(\n",
    "            img, None)\n",
    "        # Accumulate the computed descriptors\n",
    "        if descriptors is None:\n",
    "            descriptors = descriptors_img\n",
    "        else:\n",
    "            descriptors = np.vstack((descriptors, descriptors_img))\n",
    "        # print(descriptors.shape)\n",
    "\n",
    "    # save descriptors (uncomment if you want to save the computed descriptors)\n",
    "    f = open(filename_descriptors_map, 'wb')\n",
    "    pickle.dump(descriptors, f)\n",
    "    f.close()\n",
    "\n",
    "# We have extracted 50 descriptors per image, for 1000 images. The ORB descriptors have length 256\n",
    "print(descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeansClustering(descriptors, n_clusters):\n",
    "    clusterer = KMeans(n_clusters=n_clusters)\n",
    "    clusters = clusterer.fit(descriptors)\n",
    "    centroids = clusters.cluster_centers_\n",
    "\n",
    "    return centroids, clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianMixturesClustering(descriptors, n_components=8):\n",
    "    scaler = StandardScaler()\n",
    "    descriptors_scaled = scaler.fit_transform(descriptors)\n",
    "    \n",
    "    clusterer = GaussianMixture(n_components=n_components)\n",
    "    clusterer.fit(descriptors_scaled)\n",
    "    \n",
    "    return clusterer.means_, clusterer.predict(descriptors_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BisectingKMeansClustering(descriptors, n_clusters=8):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    class BisectingKMeans:\n",
    "        def __init__(self, n_clusters):\n",
    "            self.n_clusters = n_clusters\n",
    "            self.cluster_centers_ = []\n",
    "            self.labels_ = None\n",
    "\n",
    "        def fit(self, X):\n",
    "            n_clusters = self.n_clusters\n",
    "            clusters = [X]\n",
    "\n",
    "            while len(clusters) < n_clusters:\n",
    "                # Find the cluster with the highest SSE\n",
    "                sse_list = [np.sum((c - np.mean(c, axis=0))**2) for c in clusters]\n",
    "                index = np.argmax(sse_list)\n",
    "                cluster_to_split = clusters.pop(index)\n",
    "                \n",
    "                # Perform k-means with k=2 on selected cluster\n",
    "                kmeans = KMeans(n_clusters=2).fit(cluster_to_split)\n",
    "                new_clusters = [cluster_to_split[kmeans.labels_ == i] for i in range(2)]\n",
    "                \n",
    "                # Add the newly formed clusters to the list\n",
    "                clusters.extend(new_clusters)\n",
    "            \n",
    "            self.labels_ = np.zeros(X.shape[0], dtype=np.int64)\n",
    "            for i, cluster in enumerate(clusters):\n",
    "                for point in cluster:\n",
    "                    idx = np.where(np.all(X==point, axis=1))[0][0]\n",
    "                    self.labels_[idx] = i\n",
    "                self.cluster_centers_.append(np.mean(cluster, axis=0))\n",
    "\n",
    "            self.cluster_centers_ = np.array(self.cluster_centers_)\n",
    "            return self\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    descriptors_scaled = scaler.fit_transform(descriptors)\n",
    "    \n",
    "    clusterer = BisectingKMeans(n_clusters=n_clusters).fit(descriptors_scaled)\n",
    "    \n",
    "    return clusterer.cluster_centers_, clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_performance(descriptors, n_clusters=8):\n",
    "    performance_metrics = {}\n",
    "\n",
    "    # K-Means Clustering\n",
    "    if n_clusters is not None:\n",
    "        kmeans_centroids, kmeans_labels = KMeansClustering(descriptors, n_clusters)\n",
    "        # Evaluate K-Means performance\n",
    "        performance_metrics['KMeans'] = {\n",
    "            'Silhouette': silhouette_score(descriptors, kmeans_labels),\n",
    "            'Calinski-Harabasz': calinski_harabasz_score(descriptors, kmeans_labels),\n",
    "            'Davies-Bouldin': davies_bouldin_score(descriptors, kmeans_labels)\n",
    "        }\n",
    "\n",
    "        # Evaluate Gaussian Mixtures performance\n",
    "        gaussian_centroids, gaussian_labels = GaussianMixturesClustering(descriptors, n_clusters)\n",
    "        performance_metrics['GaussianMixtures'] = {\n",
    "            'Silhouette': silhouette_score(descriptors, gaussian_labels),\n",
    "            'Calinski-Harabasz': calinski_harabasz_score(descriptors, gaussian_labels),\n",
    "            'Davies-Bouldin': davies_bouldin_score(descriptors, gaussian_labels)\n",
    "        }\n",
    "\n",
    "        # Evaluate Bisecting KMeans performance\n",
    "        Bisecting_centroids, Bisecting_labels = BisectingKMeansClustering(descriptors, n_clusters)\n",
    "        performance_metrics['BisectingKMeans'] = {\n",
    "            'Silhouette': silhouette_score(descriptors, Bisecting_labels),\n",
    "            'Calinski-Harabasz': calinski_harabasz_score(descriptors, Bisecting_labels),\n",
    "            'Davies-Bouldin': davies_bouldin_score(descriptors, Bisecting_labels)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(performance_metrics):\n",
    "\n",
    "    algorithms = list(performance_metrics.keys())\n",
    "    metric_names = ['Silhouette', 'Calinski-Harabasz', 'Davies-Bouldin']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metric_names), figsize=(15, 5))\n",
    "\n",
    "    for ax, metric in zip(axes2, metric_names):\n",
    "\n",
    "        values = [performance_metrics[algorithm][metric] for algorithm in algorithms]\n",
    "\n",
    "        ax.bar(algorithms, values)\n",
    "        ax.set_title(metric)\n",
    "        ax.set_xlabel('Algorithms')\n",
    "        ax.set_ylabel('Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_8 = clustering_performance(descriptors, n_clusters=8)\n",
    "plot_performance(performance_metrics_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_30 = clustering_performance(descriptors, n_clusters=30)\n",
    "plot_performance(performance_metrics_30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
